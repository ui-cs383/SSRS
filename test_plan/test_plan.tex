\documentclass[report]{article}
\usepackage{longtable}
\usepackage{tabularx}
\usepackage{graphicx}
\usepackage
[
        left=2.5cm,
        right=2.5cm,
]
{geometry}

\newcommand{\comment}[1]{{\tt #1}}
\newcounter{rc}
\newcommand{\rn}{\stepcounter{rc}\therc}
\newcommand{\newtc}[3]{\rn & #1 & #2 & #3 \\ \hline}
\newcommand{\newut}[3]{\rn & #1 & #2 & #3 \\ \hline}

\begin{document}

\title{\textsc{Test Plan}
  \\ Freedom in the Galaxy, Python Team
  \vspace{10 mm}
  \\ Version 1.0
  \vspace{10 mm}}
  
\date{\today}

\author{Prepared for:
  \\ CS 383 Course Project
  \vspace{10 mm}
  \\Prepared by:
  \\ CS 383 Python Team
  \\ University of Idaho
  \\ Moscow, ID 83844-1010
  \vspace{10 mm}}


\maketitle
\newpage 

\begin{center}
\noindent Freedom In The Galaxy Test Plan, Python Group

\vspace{10 mm}

\noindent \textsc{Record of Changes}   

\vspace{10 mm}


\begin{tabularx}{\textwidth}{| X | X | X | X | X | X | X |}
  \hline
  \textbf{Change Number} &
    \textbf{Date Completed} &
    \textbf{Location of Change (e.g. page \# or figure \#)} &
    \textbf{Brief Description of Change} &
    \textbf{Approved by (initials)} &
    \textbf{Date Approved} 
    \\ \hline 1 & Nov 9 & ALL  & INITIAL PREP & - & -
    \\ \hline 2 & Nov 11 & Sec5.1 pg6 ; Sec6 pg6 ; Sec7 pg6 ; Sec8.5 pg6 ; Sec9 pg8-9 ; Sec9.2.1 pg9-13 & 1st Draft Review and Approval & EThom JHall & Nov 11  
    \\ \hline 3 & Nov 12-Nov25 & Integration Tests & Added Integration Tests & - & -
    \\ \hline 4 & Nov 26 & Sec 9.3;  & AI Test Cases & - & -
    \\ \hline 5 & Nov 27-Dec15 & Integration Tests & Added Integration Tests & - & -
    \\ \hline 6 & Dec 16 & Various & Reviewed Document & - & -
    \\ \hline 7 & Dec 17 & TCs & Merged Final Changes to TCs & - & -
    \\ \hline 8 & Dec 18 & Various & Changes for Review & - & -
    \\ \hline 9 & Dec 19 & Various & Review Content, Added Metrics & - & -

%    \\ \hline & & & & &  
%    \\ \hline & & & & &  
%    \\ \hline & & & & &  
    \\ \hline
\end{tabularx}
\end{center}
\newpage 
\tableofcontents
\newpage

\section[IDENTIFIER]{TEST PLAN IDENTIFIER}
FREEDOM IN THE GALAXY MASTER TEST PLAN VERSION 1.0, PYTHON GROUP
\section[REFERENCES]{REFERENCES}
Use Cases and State diagrams are available at {\tt https://github.com/Freedom-Galaxy}. Rules are contained in the SSDS available at {\tt https://github.com/SSDS}.


\section[INTRODUCTION]{INTRODUCTION}
The purpose of this test plan is to state the processes used by the Python Team in testing the Freedom in the Galaxy software project. This test plan covers the entire testing plan for the project. The Python Team is divided into three sub teams. Each sub team each has different testing requirements and should prepare documents accordingly according to the requirements stated in this document.

\section[TEST ITEMS]{TEST ITEMS}
\begin{itemize}
\item Class Interfaces
\item Class Interactions
\item User Interface Functions
\item Network Layer Functions
\item API Level Functions
\item GUI Functions
\item Requirements stated in System Software Requirement Specification
\item Requirements stated in System Software Design Documentation
\end{itemize}

\section[SOFTWARE RISK ISSUES]{SOFTWARE RISK ISSUES}
\label{risk}
Each piece of code has different levels of risk to the party. Standard library modules are usually designed to be backwards compatible are heavily tested before incorporation into the standard library, and have a high level of use. Therefore, the standard library modules have a low level of risk to this project. The tests will therefore be focused on the correct use of those modules.

Third party software has a higher level of risk than standard library and a much larger variance of quality. Some of the software has been heavily tested and some is only in a prerelease state. The level of quality of each third party module will have to be determined and testing scaled according. The level of risk can be reduced if sufficient tests are included with the library.

Testing will mainly focus on code written by Python Group members. This plan largely focuses on providing a testing plan that adequately covers both rules and implementation. As the code base is not yet complete, the complexity of the code cannot be yet determined. Also, since the documentation is often incomplete, risk also arises because of poor documentation. Complete and improved documentation of all areas of code will reduce this risk.

Finally, because the length of this project is short and is not dependent on any third party schedules, there is no to little risk from new versions of software or failure of any third party.

\subsection{Critical Risk Areas}
\begin{enumerate}
\item RPyc
\item PyGame
\item SQLAcademy
\end{enumerate} 

\section[FEATURES TO BE TESTED]{FEATURES TO BE TESTED}
\begin{center}
\begin{tabularx}{\textwidth}{| X | c |}
  \hline
  \textbf{Feature Description} &
    \textbf{Risk Level} 
\\ \hline
Start a game & High
\\ \hline
Smart AI & Low
\\ \hline
Network communication & High
\\ \hline
Play game with graphical interface & Med
\\ \hline
Play game with text interface & Low
\\ \hline
User Experience & Med
\\ \hline
\end{tabularx}
\end{center}

\section[FEATURES NOT TO BE TESTED]{FEATURES NOT TO BE TESTED}
\begin{center}
\begin{tabularx}{\textwidth}{| X | c |}
  \hline
  \textbf{Feature Description} &
    \textbf{Risk Level} 
\\ \hline
 Python Standard Library. & Low
 \\ \hline
 RPyc & Low
 \\ \hline
 SQLAcademy & Low
 \\ \hline
 PyGame & Low
 \\ \hline
 Speed of software. & Low
\\ \hline
\end{tabularx}
\end{center}


\section[APPROACH]{APPROACH}
\subsection{Testing Tools}
The testing tools for use in this project include the standard library modules doctests, unittest, and the third party tool Nose. Each tool has different levels of complexity and strengths, so each test will be written in one of these tools depending on the tester and condition.

Help will be available from other members of the team for any questions involving the testing tools in this project. Tutorials are also available on the Python website for doctest and unittest. There is no scheduled rraining for Nose.

\subsection{Metrics}
Products Metrics for this project will be the number of rules implemented. For each rule, a metric value is specified in the rules appendix of the SSDS. This metric value is a number between 1 and 10. This number is based on several criteria, such as difficulty of the rule, priority of the rule, and how close other rules are to the rule. In order to apply any metrics, the relevant TCS test must be implemented and passed. This implementation must be signed off by another member or the team and the results attached to the necessary places in the project documents. After these requirements have been completed, the metric value can be earned.

The following simple metrics have been computed:
Lines of code: 5180
Number of files: 49


\subsection{Configurations}
The AI and UI will be tested using both the Rebel and Imperial player, and all User type tests for both player types will be executed.

\subsection{Software}
The software will be developed with Python 2.7.5 with doctest and unittest of the same version. The current version of Nose is 1.3.0, the current version of Pygame is 1.2.1.

\subsection{Hardware}
The hardware specifications used for testing will be at or higher than the minimum hardware specifications for Python 2.7.5 and Pygame.

%\begin{itemize}
%\item Microsoft Windows XP Professional SP3/Vista SP1/Windows 7 Professional
%\begin{itemize}
%	\item Processor: 800MHz Intel Pentium III or equivalent
%	\item Memory: 512 MB
%	\item Disk space: 750 MB of free disk space
%\end{itemize}
%\item Ubuntu 9.10
%\begin{itemize}
%	\item Processor: 800MHz Intel Pentium III or equivalent
%	\item Memory: 512 MB
%	\item Disk space: 650 MB of free disk space
%\end{itemize}
%\item Macintosh OS X 10.6 Intel
%\begin{itemize}
%	\item Processor: Dual-Core Intel (32 or 64-bit)
%	\item Memory: 1 GB
%	\item Disk space: 650 MB of free disk space
%\end{itemize}
%\end{itemize}

\subsection{Automated Testing}
The automated test process will be divided into three phases, Unit testing, Integration testing and System testing.

\subsubsection{Unit Testing}
Unit testing will be used to validate individual classes objects. Some objects will not be required to be validated by unit testing, such as the user interface and the supporting classes and any classes or code that is exempted according to section \ref{risk}. A template is available for adding unit tests to this document.

Each team should develop TCSs as needed for their code. Each TCS should include tests for all classes as required and for each test, validate as many inputs as needed to test that the class operates as required by the rules covered in the SSRS, and also according to an requirements and design documents applicable to that class. Unit tests should focus on those test types mentioned in the lecture, such as coverage, edge cases, etc.

\subsubsection{Required Class Unit Tests}
Unit testing for each class in the final product will consist of validating the class public interface and all expected output for each class. Public variables and methods for every class are required to pass the following tests:
\begin{itemize}
\item validation using expected data input
\item validation using erroneous data input, including None or empty values
\item class instantiation
\end{itemize}

If the variable is not open to testing due to being private or otherwise not accessible to the user or other programs, such as testing, the unit instead will be considered to be the smallest practical testable unit possible.

All functionality accessible by the user must be unit tested or,if not possible tested by means of integration or systems testing, except where indicated in section \ref{risk}. This includes GUI capabilities. 

\subsubsection{Integration Testing}
Integration testing will validate the defined associations between classes. This will be an incremental process performed as new classes are created and after classes have successfully passed their unit testing phase or as necessary for deadlines. 
\paragraph{Integration Tests to be Performed}
\begin{itemize}
\item Class sets under test exhibit the relationships as defined in the class diagram
\item Methods and functions are called using the correct parameters
\item Methods and functions return the expected data types or structures.
\end{itemize}

Integration should be done at the group level. This should include mock objects or mock data to simulate any objects outside of the team as required. Integration testing should cover all reasonable combinations of objects in the game. These tests should be documented in TCSs.

\subsubsection{System Testing}
System testing will exercise the overall software product to verify conformance to defined game rules. System testing will use predefined scenarios of initial states representing possible game states that a user will encounter. Each scenario will be tested for acceptable results for each possible user action that may occur. Acceptability will be defined by the game rules. 

\subsection{Manual Testing}
Manual testing will be required for the portions of the program that can not undergo automated testing. This section applies to the testing of the user interface to simulate user orientated testing to verify conformance to the documented use cases.

\section[ITEM PASS/FAIL CRITERIA]{ITEM PASS/FAIL CRITERIA}

\subsection{Reporting a failure}

If a failure happens during the execution of any test, a failure report should be submitted to provide information of the failure. Failure should be reported in the issue page of the repository. 

The name of the issue should be the name of the name of the code file and the name of the test if applicable.

\subsubsection{What Constitutes a "failure"?}
Any deviation from a specification, e.g. SRS, UML diagrams.

\subsubsection{What Does Not Constitute a "failure"?}
Any unit or action that does not have any requirements documentation, cannot cause a 'failure'.

\subsubsection{What to do when a "failure" is discovered"?}
Produce a SCR to document each "failure" that needs to be corrected.

\subsubsection{What if a specification document is incorrect (e.g. outdated, misstated)?}
This also constitutes a "failure" and an SCR should be created.

\subsubsection{What sections to include in an SCR}

Failure Identified\\
Expected Outcome \\
Actual Behavior \\
Steps to reproduce \\

Each section should be brief and to the point, but yet convey enough information for the coder to fix the problem.

\subsection{Unit Testing Pass/Fail Criteria}
Each of these tables can be expanded to cover priority and type of test (i.e. unit, integration, system) if needed. The unit\_test\_template.tex file contains a template for all unit tests to be included in this document.

% @todo any unittests here.
% template unit_test_template.tex
\newcommand{\first}{.5cm}
\newcommand{\second}{4.5cm}
\newcommand{\third}{4.5cm}
\newcommand{\fourth}{4.5cm}

%\input{unit_test_template}
%\newpage


\subsection{Integration Testing Pass/Fail Criteria}

\input{capture_integration}
\newpage
\input{combat_integration}
\newpage
\input{game_start_integration}
\newpage
\input{gameturn_integration}
\newpage
\input{missions_integration}
\newpage
\input{movement_integration}
\newpage
\input{pdb_detection_integration}
\newpage
\input{planet_integration}
\newpage
\input{possession_integration}
\newpage
\input{searching_integration}
\newpage
\input{stacking_integration}
\newpage
\input{turn_integration}
\newpage
\input{ai_integration}

\newpage


\subsection{System Testing Pass/Fail Criteria}
None
%\input{}

\subsection{User Interface Manual Testing Pass/Fail Criteria}
None
%\input{}

\section[SUSPENSION CRITERIA]{SUSPENSION CRITERIA}
The automated testing procedure shall be completed in the following order:
\begin{enumerate}
\item Unit Testing
\item Integration Testing
\item System Testing
\end{enumerate}
Each item to be tested is required to pass each unit test of a classification of 1 with 100\% success before it can be passed to a higher level of testing. This complete success can be waived for the following reasons:
\begin{itemize}
\item Feature under test will not be included in the upcoming deliverable.
\item Feature under test will not be included in the final product.
\item Feature under test is complex and meeting the test requirements will delay the deliverable.
\end{itemize}
Decision to allow a feature to proceed to a higher level of testing shall be determined by team leader.

\section[TEST DELIVERABLES]{TEST DELIVERABLES}
\begin{itemize}
\item Test Cases
\item Test Logs
\item Incident Reports
\item Outputs
\item Corrective Actions
\end{itemize}

\subsection{Test Cases}

All unit tests, integration tests, and system tests should be documented in TCSs. The name of a TCS should match the module name (e.g. Character Class TCS) or functions (e.g. Main Menu TCS). TCS should be developed from requirements document and ideally should test every requirement of those documents.

\section[REMAINING TEST TASKS]{REMAINING TEST TASKS}

\begin{itemize}
\item Division of Labor by each group leader.
\item Implementation of testing.
\item Complication of testing results.
\end{itemize}

\section[ENVIRONMENTAL NEEDS]{ENVIRONMENTAL NEEDS}
None

\section[STAFFING AND TRAINING NEEDS]{STAFFING AND TRAINING NEEDS}
Training on portions of the project shall be carried out by the authors of the code and the documented design and the responsibility of said authors. Help is available from other members of the team.


\section[RESPONSIBILITIES]{RESPONSIBILITIES}
This document is the responsibly of the all team members who's tasks fall under the requirements of this documents, such as those assigned to write tests, etc. Robert Meine has primary responsibility of this document. Please contact Robert Meine if you have any concerns or issues with this document.


\section[SCHEDULE]{SCHEDULE}
\begin{center}
\begin{tabularx}{\textwidth}{| X | X | X |}
  \hline
  \textbf{Deliverable} &
  \textbf{Description} &
  \textbf{Due Date} 
\\ \hline
Test Plan version 1.0 & 
Completion of first draft of the complete Test Plan documentation. &
11/12/2013
\\ \hline

Test Assignment &
Assign tests to team members &
11/14/2013
\\ \hline

Delivery of Unit Tests &
Completion of assigned Unit Tests &
11/25/2013
\\ \hline

Delivery of Integration Tests &
Completion of assigned Integration Tests &
12/5/2013
\\ \hline

Delivery of System Tests and Manual Tests &
Completion of assigned System Tests &
12/10/2013
\\ \hline

Delivery of Software Metics &
Completion of assigned metrics &
12/13/2013
\\ \hline

Delivery of All SSDS SSRS related testing requirements & &
12/17/2013

\\ \hline

\end{tabularx}
\end{center}

\section[PLANNING RISKS AND CONTINGENCIES]{PLANNING RISKS AND CONTINGENCIES}
Because the end of the semester is fixed, there are no contingencies if the product does not meet requirements by that date. Public beatings will be carried out as needed.

\section[APPROVALS]{APPROVALS}

Approval is everyones responsibility since all students will be evaluated on this document.

\section[GLOSSARY]{GLOSSARY}
SCR - Software Change Request
TCS - Test Specifications Document

\end{document}
